# main.py
import feedparser
import os
import time
from datetime import datetime
from dotenv import load_dotenv
from scraper import fetch_full_content
from ai_analyst import generate_deep_dive
from publisher import save_to_hugo # å‡è¨­æˆ‘å€‘ä¹‹å¾Œå¯«é€™å€‹

load_dotenv()

# è³‡å®‰ RSS åˆ—è¡¨ (å»ºè­°é¸é«˜è³ªé‡çš„)
RSS_FEEDS = [
    "https://feeds.feedburner.com/TheHackersNews",
    "https://www.bleepingcomputer.com/feed/",
    "https://threatpost.com/feed/"
]

PROCESSED_FILE = "data/processed_urls.txt"

def load_processed():
    if not os.path.exists(PROCESSED_FILE): return set()
    with open(PROCESSED_FILE, "r") as f:
        return set(line.strip() for line in f)

def save_processed(url):
    with open(PROCESSED_FILE, "a") as f:
        f.write(f"{url}\n")

def main():
    processed_urls = load_processed()
    print(f"ğŸ“‚ å·²è™•ç†éçš„æ–‡ç« æ•¸ï¼š{len(processed_urls)}")

    for feed_url in RSS_FEEDS:
        print(f"ğŸ“¡ æ­£åœ¨æƒæ RSS: {feed_url}")
        feed = feedparser.parse(feed_url)

        for entry in feed.entries[:3]: # æ¯æ¬¡æ¯å€‹ RSS åªæŠ“æœ€æ–° 3 ç¯‡ï¼Œé¿å… API çˆ†é‡
            link = entry.link
            title = entry.title
            
            # 1. æª¢æŸ¥æ˜¯å¦è™•ç†é
            if link in processed_urls:
                continue
            
            print(f"âš¡ ç™¼ç¾æ–°æ–‡ç« ï¼š{title}")
            
            # 2. çˆ¬èŸ²ï¼šæŠ“å–å…¨æ–‡ (é—œéµæ­¥é©Ÿï¼)
            full_text = fetch_full_content(link)
            if not full_text:
                print("   âš ï¸ ç„¡æ³•æŠ“å–å…§æ–‡ï¼Œè·³éã€‚")
                continue
            
            # 3. AIï¼šæ·±åº¦åˆ†æ
            article_content = generate_deep_dive(title, full_text, link)
            if not article_content:
                continue

            # 4. ç™¼ä½ˆ (å­˜æˆ Markdown)
            # é€™è£¡æˆ‘å€‘å…ˆç°¡å–®å­˜æª”ï¼Œä¹‹å¾Œæ¥ GitHub Pages
            filename = f"website/_posts/{datetime.now().strftime('%Y-%m-%d')}-{title.replace(' ', '-').replace('/', '')}.md"
            os.makedirs(os.path.dirname(filename), exist_ok=True)
            
            with open(filename, "w", encoding="utf-8") as f:
                # åŠ ä¸Š Jekyll/Hugo éœ€è¦çš„ Front Matter
                f.write(f"---\ntitle: \"{title}\"\ndate: {datetime.now().isoformat()}\n---\n\n")
                f.write(article_content)
                
            print(f"âœ… æ–‡ç« å·²ç”Ÿæˆï¼š{filename}")
            
            # 5. è¨˜éŒ„ä¸¦å†·å»
            save_processed(link)
            print("â³ å†·å» 30 ç§’ä»¥é˜² API é™åˆ¶...")
            time.sleep(30)

if __name__ == "__main__":
    main()