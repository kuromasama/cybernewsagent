import google.generativeai as genai
from groq import Groq
import os
import time

# ================= 2026 æ¨¡åž‹é…ç½® =================
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
GEMINI_MODEL = 'models/gemini-3-flash' 
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_MODEL = 'llama-3.3-70b-versatile' 

# ================= æ ¸å¿ƒå¼•æ“Žå‡½å¼ =================

def _call_gemini(prompt):
    print(f"   âš¡ [Engine] ä½¿ç”¨ Gemini 3 Flash é€²è¡Œæ·±åº¦å‰–æž...")
    try:
        model = genai.GenerativeModel(GEMINI_MODEL)
        safety = [
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        ]
        generation_config = genai.types.GenerationConfig(
            temperature=0.15,
            max_output_tokens=16384
        )
        response = model.generate_content(prompt, safety_settings=safety, generation_config=generation_config)
        return response.text
    except Exception as e:
        print(f"   âš ï¸ Gemini ç”Ÿæˆå¤±æ•—: {e}")
        return None

def _call_groq(prompt):
    print(f"   ðŸš€ [Engine] åˆ‡æ›è‡³ Groq ({GROQ_MODEL})...")
    if not GROQ_API_KEY:
        print("   âŒ æœªè¨­å®š GROQ_API_KEY")
        return None
    try:
        client = Groq(api_key=GROQ_API_KEY)
        chat_completion = client.chat.completions.create(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä½ä¸–ç•Œç´šçš„è³‡å®‰é€†å‘å·¥ç¨‹å¸«èˆ‡å¨è„…æƒ…å ±å°ˆå®¶ã€‚"},
                {"role": "user", "content": prompt}
            ],
            model=GROQ_MODEL,
            temperature=0.1,
            max_tokens=8000,
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        print(f"   âŒ Groq ç”Ÿæˆå¤±æ•—: {e}")
        return None

# ================= ä¸»é‚è¼¯ =================

def generate_deep_dive(title, full_content, url):
    print(f"ðŸ§  AI æ­£åœ¨æ·±åº¦åˆ†æžï¼š{title}...")

    # 1. è®€å– Prompt (å„ªå…ˆå¾ž Secretï¼Œå¤±æ•—å‰‡å¾žæœ¬åœ°å‚™ä»½æª”)
    raw_prompt = os.getenv("AI_PROMPT_TEMPLATE")
    
    if not raw_prompt:
        try:
            with open("prompt_backup.txt", "r", encoding="utf-8") as f:
                raw_prompt = f.read()
            print("   ðŸ“‚ [Local] å·²è®€å–æœ¬åœ° prompt_backup.txt")
        except FileNotFoundError:
            print("   âŒ [Error] æ‰¾ä¸åˆ° AI_PROMPT_TEMPLATE ä¹Ÿæ‰¾ä¸åˆ° prompt_backup.txt")
            return None

    # 2. æ³¨å…¥è®Šæ•¸ (é—œéµæ­¥é©Ÿ)
    # å°‡ Secret ä¸­çš„ {context} æ›¿æ›ç‚ºå¯¦éš›æ–‡ç« å…§å®¹ (æˆªæ–·å‰ 60000 å­—ä»¥é˜²çˆ† Token)
    # å°‡ {url} æ›¿æ›ç‚ºå¯¦éš›ç¶²å€
    prompt = raw_prompt.replace("{context}", full_content[:60000]).replace("{url}", url)

    # --- åŸ·è¡Œç­–ç•¥ ---
    result = _call_gemini(prompt)
    
    if not result:
        print("   âš ï¸ Gemini å¤±æ•—ï¼Œå•Ÿå‹• Groq æ•‘æ´æ¨¡å¼ï¼")
        safe_len = 25000 
        if len(full_content) > safe_len:
             prompt = prompt.replace(full_content[:60000], full_content[:safe_len])
        result = _call_groq(prompt)
        
    return result